{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "For COSC 325 Project WellnessWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal vs. Other (Multiclass Classification)\n",
    "\n",
    "Multiclass classification is what we need for our model to actually be useful for our purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read in lemmatized data\n",
    "Lemmatization is important so that our data is standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           statement   status\n",
      "0                               ['oh', 'my', 'gosh']  Anxiety\n",
      "1  ['trouble', 'sleep', 'confuse', 'mind', 'restl...  Anxiety\n",
      "2  ['wrong', 'back', 'off', 'dear', 'forward', 'd...  Anxiety\n",
      "3  ['i', 'have', 'shift', 'my', 'focus', 'to', 's...  Anxiety\n",
      "4  ['i', 'restless', 'and', 'restless', 'it', 'be...  Anxiety\n"
     ]
    }
   ],
   "source": [
    "# multiclass_categories = ['Anxiety', 'Bipolar', 'Depression', 'Normal', 'Personality disorder', 'Stress', 'Suicidal'] \n",
    "\n",
    "processed_data = pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "print(processed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X to \"statement\" or tokenized equivalent \n",
    "X = processed_data[\"statement\"]\n",
    "\n",
    "# Assign y to \"status_encoded\"\n",
    "y = processed_data[\"status\"]\n",
    "\n",
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.2, # Proportion of the dataset to include in the test split (30% in this case)\n",
    "    random_state = RANDOM_STATE, # Seed for the random number generator (for reproducibility)\n",
    "    ## Stratefied sampling to ensure class balance in training and test set\n",
    "    ## (This ensures class balance in the target class labels. You may ignore this for now as we will cover this later in the class)\n",
    "    stratify = y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Bag-of-Words Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLearn Test for Bag of Words model\n",
    "\n",
    "CountVec = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
    "                           stop_words='english')\n",
    "# transform\n",
    "Count_train_data = CountVec.fit_transform(X_train)\n",
    "Count_test_data = CountVec.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.5: TF-IDF Vectorizer rather than Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFVec = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "Tf_train_data = TFVec.fit_transform(X_train)\n",
    "Tf_test_data = TFVec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Decision Tree\n",
    "1. Fit data\n",
    "2. Predict\n",
    "3. Evaluate using accuracy_score\n",
    "4. Iteratate over different values for variables such as \n",
    "    1. max_depth (e.g., 1, 3, 5, 7, 9, 11)\n",
    "    2. criteria (gini vs entropy)\n",
    "5. Determine the best input for parameters max_depth and criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_loss': [0.6338616304450982],\n",
       " 'gini': [0.6446806491411218],\n",
       " 'entropy': [0.6338616304450982]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Decision Tree model\n",
    "\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "# dt_model.fit(Count_train_data, y_train) \n",
    "# dt_prediction = dt_model.predict(Count_test_data)\n",
    "# dt_accuracy = accuracy_score(y_test, dt_prediction)\n",
    "# print(dt_accuracy)\n",
    "\n",
    "\n",
    "# Test multiple hyperparameters for decision tree model\n",
    "\n",
    "# Create a dictionary for store the choices for hyperparameter values:\n",
    "hyper_params_tree = {\n",
    "    \"max_depth\": [None], # 1, 3, 5, 7, 9, 10, 11, 15, 20, 25, 30, 35, 40, 45, 50\n",
    "    \"criterion\": [\"log_loss\", \"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Initialize the list to store accuracy scores:\n",
    "scores_tree = {\n",
    "    \"log_loss\": [],\n",
    "    \"gini\": [],\n",
    "    \"entropy\": []\n",
    "}\n",
    "\n",
    "for criterion in hyper_params_tree[\"criterion\"]:\n",
    "    accuracies = []                    # Initialize a placeholder for results of current criterion\n",
    "    for depth in hyper_params_tree[\"max_depth\"]:\n",
    "        tree_model = DecisionTreeClassifier(criterion=criterion, max_depth=depth, random_state=RANDOM_STATE)   # Define tree model based on current hyperparameter combination\n",
    "        tree_model.fit(Tf_train_data, y_train) # Fit the tree\n",
    "        y_pred = tree_model.predict(Tf_test_data) # Predict using the tree\n",
    "\n",
    "        accuracies.append(accuracy_score(y_test, y_pred)) # Calculate accuracy\n",
    "\n",
    "    # Collect accuracy score results for this configuration of hyperparameters:\n",
    "    scores_tree[criterion] = accuracies\n",
    "    \n",
    "### END SOLUTION\n",
    "\n",
    "scores_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Random Forest Classifier\n",
    "1. Fit data\n",
    "2. Predict\n",
    "3. Evaluate using accuracy_score\n",
    "4. Iteratate over different values for variables such as \n",
    "    1. The number of trees \n",
    "    2. max_depth (e.g., 1, 3, 5, 7, 9, 11)\n",
    "    3. criteria (gini vs entropy)\n",
    "5. Create a final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171585840372023\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "\n",
    "rf_model = RandomForestClassifier(criterion=\"gini\", max_depth=50, random_state=RANDOM_STATE)\n",
    "\n",
    "rf_model.fit(Tf_train_data, y_train) \n",
    "\n",
    "rf_prediction = rf_model.predict(Tf_test_data)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_prediction)\n",
    "print(rf_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6350004745183638\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree model\n",
    "# This is what was used to test \"Time Taken\"\n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=45, random_state=42)\n",
    "\n",
    "dt_model.fit(Tf_train_data, y_train) \n",
    "\n",
    "dt_prediction =dt_model.predict(Tf_test_data)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_prediction)\n",
    "print(dt_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "3. Get finished data so we can analyze\n",
    "4. max_features hyperparameter (can be pushed to post-midterm report)  \n",
    "5. upload to github!\n",
    "6. Look into Word Embeddings? (post-midterm report)\n",
    "7. Look into other models (post-midterm report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
