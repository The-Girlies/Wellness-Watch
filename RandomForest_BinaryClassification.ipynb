{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "For COSC 325 Project WellnessWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal vs. Other (Binary Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read in and filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           statement   status\n",
      "0                                         oh my gosh  Anxiety\n",
      "1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
      "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
      "3  I've shifted my focus to something else but I'...  Anxiety\n",
      "4  I'm restless and restless, it's been a month n...  Anxiety\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/The-Girlies/Wellness-Watch/main/kaggle_sentiment_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Remove the first column\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "data = data.dropna(subset=['statement', 'status'])\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Quantify data \n",
    "1. Number the categories in \"status\"\n",
    "2. Clean the text in \"statement\", removing punctuation, stop words, and converting text to lowercase\n",
    "3. Tokenize the text in \"statement\" based on words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               statement   status  \\\n",
      "0                                             oh my gosh  Anxiety   \n",
      "1      trouble sleeping, confused mind, restless hear...  Anxiety   \n",
      "2      All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
      "3      I've shifted my focus to something else but I'...  Anxiety   \n",
      "4      I'm restless and restless, it's been a month n...  Anxiety   \n",
      "...                                                  ...      ...   \n",
      "53038  Nobody takes me seriously I’ve (24M) dealt wit...  Anxiety   \n",
      "53039  selfishness  \"I don't feel very good, it's lik...  Anxiety   \n",
      "53040  Is there any way to sleep better? I can't slee...  Anxiety   \n",
      "53041  Public speaking tips? Hi, all. I have to give ...  Anxiety   \n",
      "53042  I have really bad door anxiety! It's not about...  Anxiety   \n",
      "\n",
      "       status_encoded  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "...               ...  \n",
      "53038               1  \n",
      "53039               1  \n",
      "53040               1  \n",
      "53041               1  \n",
      "53042               1  \n",
      "\n",
      "[52681 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "processed_data = data[[\"statement\", \"status\"]]\n",
    "\n",
    "# Assign the following for \"status_encoded\" column:\n",
    "# 0 - Normal\n",
    "# 1 - Other\n",
    "# categories = [\"Normal\", \"Other\"]  # multiclass_categories = ['Anxiety', 'Bipolar', 'Depression', 'Normal', 'Personality disorder', 'Stress', 'Suicidal'] \n",
    "processed_data = processed_data.assign(status_encoded = [0 if status == \"Normal\" else 1 for status in processed_data[\"status\"]])\n",
    "\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahuan\\AppData\\Local\\Temp\\ipykernel_32624\\2271632757.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_data.iloc[s][\"statement\"] = tokenized_string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               statement   status  \\\n",
      "0                                             oh my gosh  Anxiety   \n",
      "1      trouble sleeping, confused mind, restless hear...  Anxiety   \n",
      "2      All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
      "3      I've shifted my focus to something else but I'...  Anxiety   \n",
      "4      I'm restless and restless, it's been a month n...  Anxiety   \n",
      "...                                                  ...      ...   \n",
      "53038  Nobody takes me seriously I’ve (24M) dealt wit...  Anxiety   \n",
      "53039  selfishness  \"I don't feel very good, it's lik...  Anxiety   \n",
      "53040  Is there any way to sleep better? I can't slee...  Anxiety   \n",
      "53041  Public speaking tips? Hi, all. I have to give ...  Anxiety   \n",
      "53042  I have really bad door anxiety! It's not about...  Anxiety   \n",
      "\n",
      "       status_encoded  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "...               ...  \n",
      "53038               1  \n",
      "53039               1  \n",
      "53040               1  \n",
      "53041               1  \n",
      "53042               1  \n",
      "\n",
      "[52681 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# my processing actually kinda mucks things up... spaces get removed and you end up with \"words\" like 'goodjealousanxiousdisappointedfeeling'\n",
    "# test1 and test3 have removing punctuation except apostrophes and removing double spaces \n",
    "# test2 had the tokenization all commented out   (control... no filtering)\n",
    "# test4 commented out the re.sub lines removing punctuation except apostrophes and removing double spaces \n",
    "# test5 commented out the removing punctuation except apostrophes, leaving only the removing double spaces \n",
    "# test2 and test4 and test5 had the exact same results\n",
    "\n",
    "# therefore, double spaces do not affect the results\n",
    "# need to compare removing all punctuation except and including apostrophes with each other and with control \n",
    "# test6 includes removes all punctuation, and has the one making an exception for apostrophes commented out\n",
    "# test7 fixes contractions but also removes all punctuation except apostrophes and removes double spaces\n",
    "# test7 produces the same results as test2 and therefore test4 and test5\n",
    "\n",
    "\n",
    "\n",
    "# Clean the text in \"statement\", removing punctuation, stop words, and converting text to lowercase\n",
    "# Tokenize the text in \"statement\", splitting the text into individual words\n",
    "for s in range(len(processed_data[\"statement\"])):\n",
    "    string = processed_data.iloc[s][\"statement\"]\n",
    "    string = contractions.fix(string)\n",
    "    string = string.lower()\n",
    "    # string = re.sub(r\"[^\\w\\s]\", '', string) # removes all punctuation \n",
    "    string = re.sub(r\"[^\\w\\s']\", '', string) # removes all punctuation except apostrophes\n",
    "    string = re.sub(r'\\s+', ' ', string) # removes double spaces\n",
    "    tokenized_string = nltk.word_tokenize(string)\n",
    "\n",
    "    processed_data.iloc[s][\"statement\"] = tokenized_string\n",
    "    # processed_data.iloc[s][\"statement\"] = string\n",
    "print(processed_data)\n",
    "\n",
    "# # Word Counter in case you want to sort most commonly used words\n",
    "# word2count = {} \n",
    "# for data in processed_data[\"statement\"]: \n",
    "#     words = nltk.word_tokenize(data) \n",
    "#     for word in words: \n",
    "#         if word not in word2count.keys(): \n",
    "#             word2count[word] = 1\n",
    "#         else: \n",
    "#             word2count[word] += 1\n",
    "\n",
    "# print(word2count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X to \"statement\" or tokenized equivalent \n",
    "X = processed_data[\"statement\"]\n",
    "\n",
    "# Assign y to \"status_encoded\"\n",
    "y = processed_data[\"status_encoded\"]\n",
    "\n",
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.2, # Proportion of the dataset to include in the test split (30% in this case)\n",
    "    random_state = RANDOM_STATE, # Seed for the random number generator (for reproducibility)\n",
    "    ## Stratefied sampling to ensure class balance in training and test set\n",
    "    ## (This ensures class balance in the target class labels. You may ignore this for now as we will cover this later in the class)\n",
    "    stratify = y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Bag-of-Words Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(max_features=1000)  # Limit vocabulary size\n",
    "\n",
    "# X_train_bow = vectorizer.fit_transform(train_text)  # Transform training data\n",
    "\n",
    "# SKLearn Test for Bag of Words model\n",
    "\n",
    "CountVec = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
    "                           stop_words='english')\n",
    "# transform\n",
    "Count_train_data = CountVec.fit_transform(X_train)\n",
    "Count_test_data = CountVec.transform(X_test)\n",
    "\n",
    "# feat_dict = CountVec.vocabulary_.keys()\n",
    "# print(feat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Decision Tree\n",
    "1. Fit data\n",
    "2. Predict\n",
    "3. Evaluate using accuracy_score\n",
    "4. Iteratate over different values for variables such as \n",
    "    1. max_depth (e.g., 1, 3, 5, 7, 9, 11)\n",
    "    2. criteria (gini vs entropy vs log_loss)\n",
    "5. Determine the best input for parameters max_depth and criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_loss': [0.9085128594476606,\n",
       "  0.9078485337382557,\n",
       "  0.9069944006833064,\n",
       "  0.9113599696308247,\n",
       "  0.9111701622852805]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Decision Tree model\n",
    "\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "# dt_model.fit(Count_train_data, y_train) \n",
    "# dt_prediction = dt_model.predict(Count_test_data)\n",
    "# dt_accuracy = accuracy_score(y_test, dt_prediction)\n",
    "# print(dt_accuracy)\n",
    "\n",
    "\n",
    "# Test multiple hyperparameters for decision tree model\n",
    "\n",
    "# Create a dictionary for store the choices for hyperparameter values:\n",
    "hyper_params_tree = {\n",
    "    \"max_depth\": [50, 55, 60, 65, 70],\n",
    "    \"criterion\": [\"log_loss\"]\n",
    "}\n",
    "\n",
    "# Initialize the list to store accuracy scores:\n",
    "scores_tree = {\n",
    "    \"log_loss\": []\n",
    "}\n",
    "\n",
    "for criterion in hyper_params_tree[\"criterion\"]:\n",
    "    accuracies = []                    # Initialize a placeholder for results of current criterion\n",
    "    for depth in hyper_params_tree[\"max_depth\"]:\n",
    "        tree_model = DecisionTreeClassifier(criterion=criterion, max_depth=depth, random_state=RANDOM_STATE)   # Define tree model based on current hyperparameter combination\n",
    "        tree_model.fit(Count_train_data, y_train) # Fit the tree\n",
    "        y_pred = tree_model.predict(Count_test_data) # Predict using the tree\n",
    "\n",
    "        accuracies.append(accuracy_score(y_test, y_pred)) # Calculate accuracy\n",
    "\n",
    "    # Collect accuracy score results for this configuration of hyperparameters:\n",
    "    scores_tree[criterion] = accuracies\n",
    "    \n",
    "### END SOLUTION\n",
    "\n",
    "scores_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Random Forest Classifier\n",
    "1. Fit data\n",
    "2. Predict\n",
    "3. Evaluate using accuracy_score\n",
    "4. Iteratate over different values for variables such as \n",
    "    1. The number of trees \n",
    "    2. max_depth (e.g., 1, 3, 5, 7, 9, 11)\n",
    "    3. criteria (gini vs entropy)\n",
    "5. Create a final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9212299515991269\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "\n",
    "rf_model = RandomForestClassifier(criterion=\"log_loss\", max_depth=65, random_state=RANDOM_STATE)\n",
    "\n",
    "rf_model.fit(Count_train_data, y_train) \n",
    "\n",
    "rf_prediction = rf_model.predict(Count_test_data)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_prediction)\n",
    "print(rf_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. Do Random Forest + Decision Tree on Kaylee's lemmatized data! Important so that data is standardized\n",
    "2. Figure out MULTI-CLASS CLASSIFICATION! This is what we need for our model to actually be useful for our purpose\n",
    "3. max_features hyperparameter (can be pushed to post-midterm report) \n",
    "4. upload to github! \n",
    "5. Get finished data so we can analyze\n",
    "\n",
    "\n",
    "\n",
    "1. Use TF-IDF instead of CountVectorizer\n",
    "2. Look into Word Embeddings\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
